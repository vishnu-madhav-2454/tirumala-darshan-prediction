% ============================================================================
%  Tirumala Darshan Crowd Advisory — Research Paper
%  An Ensemble Machine-Learning Framework for Daily Pilgrim-Flow
%  Band Prediction at Tirumala Tirupati Devasthanams
% ============================================================================
\documentclass[12pt,a4paper,twocolumn]{article}

% ── Packages ──────────────────────────────────────────────────────────────────
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage[margin=2cm]{geometry}
\usepackage{amsmath,amssymb}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{array}
\usepackage{tabularx}
\usepackage{float}
\usepackage{hyperref}
\usepackage{cleveref}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{enumitem}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{xcolor}
\usepackage{colortbl}
\usepackage{url}
\usepackage{cite}
\usepackage{microtype}
\usepackage{mathtools}

\hypersetup{
  colorlinks=true,
  linkcolor=blue!70!black,
  citecolor=green!50!black,
  urlcolor=blue!60!black
}

% ── Custom Commands ───────────────────────────────────────────────────────────
\newcommand{\tirumala}{\textsc{Tirumala}}
\newcommand{\systemname}{\textsc{TiruCrowdAdvisor}}
\newcommand{\band}[1]{\texttt{#1}}

% ── Title ─────────────────────────────────────────────────────────────────────
\title{%
  \Large\textbf{An Ensemble Gradient-Boosting Framework with Ordinal-Aware
  Scoring for Daily Pilgrim Crowd-Band Prediction at Tirumala}\\[6pt]
  \large A Full-Stack ML Pipeline with Festival Calendar Integration,
  Autoregressive Forecasting, and Online Learning
}

\author{
  \textbf{Authors}\\
  Independent Research\\
  \texttt{tirumala-darshan-prediction}
}

\date{\today}

% ============================================================================
\begin{document}
\maketitle

% ── Abstract ──────────────────────────────────────────────────────────────────
\begin{abstract}
Tirumala Tirupati Devasthanams (TTD) receives 50,000--120,000 pilgrims daily,
making crowd prediction essential for travel planning and temple resource
allocation. We present \systemname{}, an end-to-end machine-learning system
that classifies daily pilgrim flow into six ordinal crowd bands
(\band{QUIET} through \band{EXTREME}) using a calibrated three-model
ensemble of Gradient Boosting, LightGBM, and XGBoost. Our pipeline
encompasses (i)~domain-driven feature engineering with 57 leakage-free
features distilled to 16 via a 10-method consensus vote, (ii)~Optuna
Bayesian hyperparameter optimization over 80 trials per model with a custom
ordinal-aware composite scoring function, (iii)~a safety-conscious class
weighting scheme that up-weights rare but critical \band{HEAVY}/\band{EXTREME}
bands, (iv)~deterministic festival calendar floor logic for Brahmotsavams,
Vaikuntha Ekadashi, and Sankranti, and (v)~an online daily warm-start
retraining pipeline. On a held-out stratified test set of 221~days, the
ensemble achieves \textbf{59.7\% accuracy} on individual models (GB) and
\textbf{57.0\% ensemble accuracy} across all six classes, with a
\textbf{100\% safety score} (zero dangerous under-predictions). On a pure
temporal split, we compare against Seasonal Na\"ive, Prophet, and SARIMA
baselines, demonstrating that our ensemble (64.6\%) decisively outperforms
Prophet (8.0\%) and SARIMA (46.2\%) while remaining competitive with the
Seasonal Na\"ive baseline (66.2\%), which lacks festival awareness and
safety constraints. The system is deployed as a responsive web application
with daily online retraining.
\end{abstract}

\noindent\textbf{Keywords:} crowd prediction, ensemble learning, gradient boosting,
ordinal classification, temple crowd management, LightGBM, XGBoost,
feature selection, time series, online learning

% ============================================================================
\section{Introduction}
\label{sec:intro}

The Sri Venkateswara Temple at Tirumala, Andhra Pradesh, is one of the most
visited religious sites globally, receiving an estimated 20--30 million
pilgrims annually~\cite{ttd_stats}. Daily footfall ranges from under 50,000
on quiet weekdays to over 100,000 during major Hindu festivals such as
Brahmotsavams, Vaikuntha Ekadashi, and Makar Sankranti. This extreme
variability creates significant challenges for pilgrims planning their visit
and for the Tirumala Tirupati Devasthanams (TTD) administration in managing
queues, accommodation, and \textit{prasadam} distribution.

Accurate crowd prediction can substantially improve the pilgrim experience by
enabling visitors to avoid overcrowded periods and helping TTD allocate
resources proactively. However, this prediction problem presents several
unique challenges:

\begin{enumerate}[nosep]
  \item \textbf{Ordinal target}: Crowd levels are naturally ordered
    (\band{QUIET} $<$ \band{LIGHT} $<$ \cdots $<$ \band{EXTREME});
    standard classification metrics overlook this ordering.
  \item \textbf{Severe class imbalance}: \band{EXTREME} comprises only
    $\sim$1.3\% of samples (14/1104), while \band{QUIET} accounts for
    $\sim$0.7\% (8/1104).
  \item \textbf{Safety asymmetry}: Under-predicting a \band{HEAVY} day as
    \band{QUIET} is far more harmful than the converse, as pilgrims may
    arrive unprepared for 8--12 hour queues.
  \item \textbf{Festival-driven non-stationarity}: Hindu lunar/solar
    festivals cause abrupt, calendar-driven spikes that lag-based models
    struggle to anticipate for far-future dates.
  \item \textbf{Limited data}: Post-COVID data (February 2022 onward) spans
    only $\sim$1,100 usable samples after feature engineering.
\end{enumerate}

In this paper, we describe the complete \systemname{} pipeline—from data
collection through deployment—addressing each challenge with tailored
engineering decisions. Our contributions are:

\begin{itemize}[nosep]
  \item A \textbf{10-method consensus feature selection} framework that
    distills 57 features to 16 with a 69:1 sample-to-feature ratio.
  \item A \textbf{custom ordinal composite scoring function} combining exact
    accuracy, macro-F1, ordinal penalty, and safety score.
  \item A \textbf{calibrated three-model ensemble} (GB/LightGBM/XGBoost)
    with grid-searched weights on a dedicated calibration split.
  \item \textbf{Deterministic festival floor logic} that guarantees minimum
    crowd bands during known high-traffic religious events.
  \item A \textbf{daily online warm-start retraining} pipeline with
    autoregressive multi-step forecasting and confidence decay.
  \item A comprehensive comparison against Seasonal Na\"ive, Prophet, and
    SARIMA baselines.
\end{itemize}

% ============================================================================
\section{Related Work}
\label{sec:related}

Crowd prediction at religious and tourist sites has been explored using
classical time-series methods (ARIMA, SARIMA, Prophet)~\cite{prophet_paper},
as well as machine-learning approaches including Random Forests and gradient
boosting~\cite{crowd_ml}. However, most studies treat the problem as
regression (predicting exact counts) rather than ordinal classification
(predicting crowd bands), and few incorporate domain-specific festival
calendars or safety-asymmetric loss functions.

Ensemble gradient-boosting methods—particularly LightGBM~\cite{lightgbm}
and XGBoost~\cite{xgboost}—have demonstrated state-of-the-art performance
on tabular classification tasks~\cite{tabular_survey}. Feature selection
via consensus voting across multiple methods has been shown to improve
generalization compared to single-method approaches~\cite{feat_sel_survey}.

% ============================================================================
\section{Data}
\label{sec:data}

\subsection{Source and Collection}

Daily pilgrim count data is scraped from the official TTD website, which
publishes the previous day's total darshan (worship viewing) count. Our
dataset spans from January 2020 to February 2026, comprising 4,076 raw
records.

\subsection{Preprocessing}

\begin{enumerate}[nosep]
  \item \textbf{COVID filtering}: Records before February 1, 2022 are
    discarded due to lockdown-era anomalies, yielding $\sim$1,469 valid
    date-count pairs.
  \item \textbf{Outlier removal}: Extreme outliers (temple closure days,
    data errors) are removed in the source CSV
    (\texttt{CLEAN\_NO\_OUTLIERS}).
  \item \textbf{Feature engineering} (Section~\ref{sec:features}) produces
    1,104 complete samples after dropping rows with NaN values from
    lag/rolling computations.
\end{enumerate}

\subsection{Target Variable: Crowd Bands}

Rather than predicting exact pilgrim counts, we discretize the daily total
into six ordered bands (Table~\ref{tab:bands}), motivated by TTD's own
informal categorization and the practical needs of pilgrims.

\begin{table}[h]
\centering
\caption{Crowd band definitions and class distribution.}
\label{tab:bands}
\begin{tabular}{@{}clccc@{}}
\toprule
\textbf{ID} & \textbf{Band} & \textbf{Range} & \textbf{Count} & \textbf{\%} \\
\midrule
0 & \band{QUIET}    & 0--50K      & 8    & 0.7 \\
1 & \band{LIGHT}    & 50K--60K    & 159  & 14.4 \\
2 & \band{MODERATE} & 60K--70K    & 403  & 36.5 \\
3 & \band{BUSY}     & 70K--80K    & 320  & 29.0 \\
4 & \band{HEAVY}    & 80K--90K    & 200  & 18.1 \\
5 & \band{EXTREME}  & 90K+        & 14   & 1.3  \\
\bottomrule
\end{tabular}
\end{table}

The severe imbalance—98.6\% of samples fall in the middle four bands while
\band{EXTREME} has only 14 samples—necessitates careful stratification
and class weighting strategies.

% ============================================================================
\section{Feature Engineering}
\label{sec:features}

We construct 57 leakage-free features organized into eight groups. All
temporal features use explicit \texttt{.shift(N)} operations to prevent
look-ahead bias.

\subsection{Calendar Features (6)}
\begin{itemize}[nosep]
  \item \texttt{dow}: Day of week (Monday=0, Sunday=6)
  \item \texttt{month}: Month number (1--12)
  \item \texttt{is\_weekend}: Binary indicator for Saturday/Sunday
  \item \texttt{sin\_doy}, \texttt{cos\_doy}: Fourier encoding of the
    annual cycle $\bigl(\sin\frac{2\pi \cdot d}{365},\;
    \cos\frac{2\pi \cdot d}{365}\bigr)$
  \item \texttt{week\_of\_year}: ISO week number
\end{itemize}

\subsection{Lag Features (7)}
\begin{itemize}[nosep]
  \item \texttt{L1}, \texttt{L2}: Yesterday's and day-before-yesterday's count
  \item \texttt{L7}: Same day last week
  \item \texttt{L14}, \texttt{L21}, \texttt{L28}: Same day 2/3/4 weeks ago
  \item \texttt{L365}: Same day last year (annual memory)
\end{itemize}

\subsection{Rolling Statistics (5)}
\begin{itemize}[nosep]
  \item \texttt{rm7}, \texttt{rm14}, \texttt{rm30}: Rolling mean over
    7/14/30 days (shifted by 1)
  \item \texttt{rstd7}, \texttt{rstd14}: Rolling standard deviation
    (volatility measures)
\end{itemize}

\subsection{Expanding Day-of-Week Means (2)}
\begin{itemize}[nosep]
  \item \texttt{dow\_expanding\_mean}: Historical mean count for each
    weekday (expanding window)
  \item \texttt{month\_dow\_mean}: Month $\times$ weekday interaction mean
    (captures seasonal weekday patterns)
\end{itemize}

\subsection{Log Transforms (5)}
To reduce right-skew for tree-based splits:
\texttt{log\_L1}, \texttt{log\_L7}, \texttt{log\_rm7}, \texttt{log\_rm30},
\texttt{log\_L365} $= \log_e(x + 1)$.

\subsection{Derived and Interaction Features (9)}
\begin{itemize}[nosep]
  \item \texttt{momentum\_7}: $\text{rm7} - \text{rm14}$ (short-term trend)
  \item \texttt{dow\_dev}: Deviation from weekday historical mean
  \item \texttt{ewm7}, \texttt{ewm14}: Exponentially weighted means
    (7 and 14-day half-life)
  \item \texttt{trend\_7\_14}, \texttt{trend\_7\_30}: Ratio-based trend
    indicators
  \item \texttt{yoy\_growth}: Year-over-year growth rate
  \item \texttt{month\_weekend}: Interaction of month and weekend indicator
  \item \texttt{month\_dow}: Month $\times$ day-of-week combination
\end{itemize}

\subsection{Regime Counts (2)}
\begin{itemize}[nosep]
  \item \texttt{heavy\_extreme\_count7}: Number of \band{HEAVY}/\band{EXTREME}
    days in the past 7 days (``hot streak'' detector)
  \item \texttt{light\_quiet\_count7}: Number of \band{LIGHT}/\band{QUIET}
    days in the past 7 days
\end{itemize}

\subsection{Festival Features ($\sim$21)}
\begin{itemize}[nosep]
  \item Binary indicators: \texttt{is\_festival}, \texttt{is\_brahmotsavam},
    \texttt{is\_sankranti}, \texttt{is\_vaikuntha\_ekadashi}, etc.
  \item Continuous: \texttt{fest\_impact} (1--10 scale),
    \texttt{days\_to\_fest}, \texttt{days\_from\_fest}
  \item Window features: \texttt{fest\_window\_3}, \texttt{fest\_window\_7}
    (upcoming festival proximity)
\end{itemize}

\noindent\textbf{Design note}: Lunar calendar features (\texttt{is\_pournami},
\texttt{is\_amavasya}) are excluded because the Hindu calendar module covers
only 2025--2027, which would yield zeros for 75\% of the training period
(2022--2025).

% ============================================================================
\section{Feature Selection}
\label{sec:feat_sel}

With 57 features and only 1,104 samples, overfitting is a significant risk.
We employ a \textbf{10-method consensus vote} framework, inspired by
ensemble principles from model selection~\cite{feat_sel_survey}.

\subsection{Selection Methods}

Each method independently ranks all features. A feature receives a vote from
a method if its score exceeds that method's median threshold:

\begin{enumerate}[nosep]
  \item \textbf{Mutual Information} (MI)
  \item \textbf{ANOVA F-test}
  \item \textbf{Chi-squared} (after MinMax scaling to $[0,1]$)
  \item \textbf{GradientBoosting impurity importance}
  \item \textbf{Random Forest importance}
  \item \textbf{Extra Trees importance}
  \item \textbf{Permutation importance} (on a separate GB model)
  \item \textbf{L1 Logistic Regression} (sum of abs coefficients across OvR)
  \item \textbf{Spearman rank correlation} (max $|\rho|$ with target)
  \item \textbf{Recursive Feature Elimination} (DecisionTree-based)
\end{enumerate}

\subsection{Consensus Rules}

\begin{enumerate}[nosep]
  \item \textbf{Variance pre-filter}: Drop features where $\geq$98\% of
    values are identical.
  \item \textbf{Voting threshold}: A feature is \emph{kept} if $\geq 6/10$
    methods vote for it.
  \item \textbf{Redundancy removal}: If two retained features have Spearman
    $|\rho| > 0.95$, drop the one with fewer votes (tie-break: lower MI).
  \item \textbf{Bounds}: Retain between 15 and 40 features.
\end{enumerate}

This process yields \textbf{16 features} (Table~\ref{tab:features}),
improving the sample-to-feature ratio from 19.4:1 to 69.0:1.

\begin{table}[h]
\centering
\caption{The 16 selected features with consensus vote counts.}
\label{tab:features}
\small
\begin{tabular}{@{}lll@{}}
\toprule
\textbf{Feature} & \textbf{Group} & \textbf{Description} \\
\midrule
\texttt{dow}                & Calendar  & Day of week \\
\texttt{cos\_doy}           & Calendar  & Annual cycle (cosine) \\
\texttt{L14}                & Lag       & Count 2 weeks ago \\
\texttt{L21}                & Lag       & Count 3 weeks ago \\
\texttt{L28}                & Lag       & Count 4 weeks ago \\
\texttt{rm14}               & Rolling   & 14-day rolling mean \\
\texttt{rstd7}              & Rolling   & 7-day rolling std dev \\
\texttt{dow\_expanding\_mean} & Expanding & Weekday historical avg \\
\texttt{month\_dow\_mean}   & Expanding & Month$\times$DOW mean \\
\texttt{log\_L1}            & Log       & $\log(\text{L1}+1)$ \\
\texttt{log\_L7}            & Log       & $\log(\text{L7}+1)$ \\
\texttt{log\_rm7}           & Log       & $\log(\text{rm7}+1)$ \\
\texttt{log\_rm30}          & Log       & $\log(\text{rm30}+1)$ \\
\texttt{ewm7}               & Derived   & 7-day EWM \\
\texttt{month\_weekend}     & Interaction & Month$\times$weekend \\
\texttt{heavy\_extreme\_count7} & Regime & Heavy/Extreme streak \\
\bottomrule
\end{tabular}
\end{table}

% ============================================================================
\section{Methodology}
\label{sec:method}

\subsection{Data Splitting Strategy}

Given the extreme class imbalance (only 14 \band{EXTREME} and
8 \band{QUIET} samples), a standard temporal train/test split would result
in one or more classes being entirely absent from the training set. We
therefore use \texttt{StratifiedShuffleSplit} with the allocation shown in
Table~\ref{tab:split}.

\begin{table}[h]
\centering
\caption{Data split allocation.}
\label{tab:split}
\begin{tabular}{@{}lcc@{}}
\toprule
\textbf{Subset} & \textbf{Size} & \textbf{Purpose} \\
\midrule
Train       & 794 (72\%) & Model fitting \\
Calibration & 89 (8\%)   & Ensemble weight optimization \\
Test        & 221 (20\%) & Final untouched evaluation \\
\bottomrule
\end{tabular}
\end{table}

\noindent\textbf{Temporal integrity}: Features are computed in strict
temporal order using \texttt{.shift(N)} \textit{before} the stratified
split. This ensures that no future information leaks into any sample's
feature vector, regardless of the sample's split assignment. A separate
walk-forward evaluation (Section~\ref{sec:walkforward}) provides an
honest temporal out-of-sample metric.

\subsection{Scoring Function}
\label{sec:scoring}

Standard classification metrics (accuracy, F1) fail to capture the ordinal
and safety-asymmetric nature of crowd prediction. We define a \textbf{custom
composite score}:

\begin{equation}
\label{eq:score}
S = 0.30 \cdot A_{\text{exact}} + 0.30 \cdot F_{\text{macro}}
  + 0.25 \cdot O + 0.15 \cdot \text{Safety}
\end{equation}

\noindent where:
\begin{itemize}[nosep]
  \item $A_{\text{exact}}$: Standard multiclass accuracy
  \item $F_{\text{macro}}$: Macro-averaged F1 across all 6 classes
  \item $O = 1 - \frac{\text{MAE}}{N_{\text{bands}} - 1}$: \textbf{Ordinal
    penalty}---penalizes off-by-2 predictions more than off-by-1
  \item $\text{Safety} = 1 - \frac{n_{\text{danger}}}{N}$: Fraction of
    samples that are \textit{not} dangerous under-predictions (predicting
    \band{QUIET}/\band{LIGHT} when the actual band is
    \band{HEAVY}/\band{EXTREME})
\end{itemize}

\subsection{Class Weighting}

To address imbalance, we compute balanced class weights:
\begin{equation}
w_c = \frac{N_{\text{train}}}{N_{\text{classes}} \times n_c}
\end{equation}
with an additional \textbf{1.5$\times$ safety multiplier} for
\band{HEAVY} (band~4) and \band{EXTREME} (band~5):
\begin{equation}
w_c' = \begin{cases}
  1.5 \cdot w_c & \text{if } c \in \{4, 5\} \\
  w_c & \text{otherwise}
\end{cases}
\end{equation}

These weights are applied as \texttt{sample\_weight} during training and
recomputed per fold during cross-validation.

\subsection{Phase 1: Baseline Models}

Three gradient-boosting classifiers are trained with sensible default
hyperparameters:

\begin{itemize}[nosep]
  \item \textbf{GradientBoostingClassifier} (scikit-learn): 500 estimators,
    max\_depth=5, learning\_rate=0.05, subsample=0.8
  \item \textbf{LightGBM}: 500 estimators, max\_depth=6,
    learning\_rate=0.05, num\_leaves=31
  \item \textbf{XGBoost}: 500 estimators, max\_depth=5,
    learning\_rate=0.05, subsample=0.8
\end{itemize}

Each model undergoes 5-fold \texttt{StratifiedKFold} cross-validation using
the composite score (Eq.~\ref{eq:score}) as the optimization target. Phase~1
results serve as the baseline for measuring Optuna-driven improvement.

\subsection{Phase 2: Bayesian Hyperparameter Optimization}

We use \textbf{Optuna}~\cite{optuna} with the Tree-structured Parzen
Estimator (TPE) sampler to tune each model over \textbf{80 trials}. The
search spaces are summarized in Table~\ref{tab:optuna}.

\begin{table}[h]
\centering
\caption{Optuna search spaces for each model.}
\label{tab:optuna}
\small
\begin{tabular}{@{}lll@{}}
\toprule
\textbf{Parameter} & \textbf{Range} & \textbf{Scale} \\
\midrule
\multicolumn{3}{@{}l}{\textit{Common to all three models}} \\
n\_estimators     & 200--1000 & Linear \\
max\_depth        & 3--7 (GB), 3--10 (LGB/XGB) & Linear \\
learning\_rate    & 0.005--0.15 & Log \\
subsample         & 0.6--1.0 & Uniform \\
\midrule
\multicolumn{3}{@{}l}{\textit{GB-specific}} \\
min\_samples\_split  & 5--30 & Linear \\
min\_samples\_leaf   & 3--20 & Linear \\
max\_features     & \{sqrt, log2\} & Categorical \\
\midrule
\multicolumn{3}{@{}l}{\textit{LightGBM / XGBoost}} \\
colsample\_bytree & 0.5--1.0 & Uniform \\
reg\_alpha        & $10^{-3}$--10 & Log \\
reg\_lambda       & $10^{-3}$--10 & Log \\
num\_leaves (LGB) & 15--127 & Linear \\
gamma (XGB)       & 0--5 & Uniform \\
min\_child\_weight (XGB) & 1--20 & Linear \\
\bottomrule
\end{tabular}
\end{table}

\noindent LightGBM uses \texttt{early\_stopping\_rounds=30} during each CV
fold to prevent overfitting.

\subsection{Tuned Hyperparameters}

Table~\ref{tab:tuned_hp} shows the best hyperparameters found by Optuna.

\begin{table}[h]
\centering
\caption{Best hyperparameters from 80 Optuna trials.}
\label{tab:tuned_hp}
\small
\begin{tabular}{@{}llll@{}}
\toprule
\textbf{Param} & \textbf{GB} & \textbf{LGB} & \textbf{XGB} \\
\midrule
n\_estimators     & 685  & 667  & 913 \\
max\_depth        & 6    & 8    & 4 \\
learning\_rate    & 0.006 & 0.081 & 0.032 \\
subsample         & 0.743 & 0.882 & 0.691 \\
min\_samples\_split & 19 & --- & --- \\
min\_samples\_leaf  & 13 & --- & --- \\
max\_features     & log2 & --- & --- \\
num\_leaves       & --- & 125 & --- \\
min\_child\_samples & --- & 5 & --- \\
colsample\_bytree & --- & 0.543 & 0.766 \\
reg\_alpha        & --- & 0.002 & 0.127 \\
reg\_lambda       & --- & 0.290 & 0.010 \\
min\_child\_weight & --- & --- & 6 \\
gamma             & --- & --- & 0.905 \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Ensemble Calibration}

The three models are combined via a \textbf{weighted probability average}:
\begin{equation}
\hat{y} = \arg\max_c \Bigl(
  w_{\text{GB}} \cdot P_{\text{GB}}(c) +
  w_{\text{LGB}} \cdot P_{\text{LGB}}(c) +
  w_{\text{XGB}} \cdot P_{\text{XGB}}(c)
\Bigr)
\end{equation}

Weights are determined by an exhaustive grid search over
$w_{\text{GB}} \in [0.10, 0.65]$ (step 0.05) and
$w_{\text{LGB}} \in [0.10, 0.65]$ (step 0.05) with
$w_{\text{XGB}} = 1 - w_{\text{GB}} - w_{\text{LGB}}$, optimizing the
composite score on the \textbf{calibration set} (89 samples, never used
for training or testing).

The optimal weights are:
\begin{equation}
w_{\text{GB}} = 0.10, \quad w_{\text{LGB}} = 0.50, \quad
w_{\text{XGB}} = 0.40
\end{equation}

% ============================================================================
\section{Results}
\label{sec:results}

\subsection{Phase 2 Test Set Performance}

Table~\ref{tab:results} summarizes the performance of each model and the
ensemble on the 221-sample held-out test set.

\begin{table}[h]
\centering
\caption{Phase 2 (Optuna-tuned) test set results (221 days).}
\label{tab:results}
\small
\begin{tabular}{@{}lccccc@{}}
\toprule
\textbf{Model} & \textbf{Accuracy} & \textbf{F1\textsubscript{macro}} & \textbf{MAE} & \textbf{Safety} & \textbf{Danger} \\
\midrule
GB  & 59.7\% & 37.8\% & 0.434 & 100\% & 0 \\
LGB & 54.3\% & 31.5\% & 0.480 & 100\% & 0 \\
XGB & 56.6\% & 35.8\% & 0.484 & 100\% & 0 \\
\rowcolor{green!10}
\textbf{ENS} & \textbf{57.0\%} & \textbf{34.5\%} & \textbf{0.457} & \textbf{100\%} & \textbf{0} \\
\bottomrule
\end{tabular}
\end{table}

\noindent Key observations:
\begin{itemize}[nosep]
  \item \textbf{GB achieves the highest accuracy at 59.7\%}, followed by
    the ensemble at 57.0\% and XGB at 56.6\%. The ensemble trades a small
    amount of peak accuracy for greater robustness and stability across all
    six classes.
  \item \textbf{100\% safety score}: Zero cases where the system predicts
    \band{QUIET} or \band{LIGHT} when the actual crowd is \band{HEAVY} or
    \band{EXTREME}.
  \item The 57\% accuracy across six fine-grained bands reflects the
    inherent difficulty of distinguishing adjacent bands (e.g., 69K vs.\ 71K
    pilgrims)---a distinction that has minimal practical impact for visitors.
  \item GB's highest accuracy (59.7\%) is notable, but LGB's stronger
    generalization and XGB's complementary strengths justify the ensemble
    approach for production stability.
\end{itemize}

\subsection{Walk-Forward Temporal Evaluation}
\label{sec:walkforward}

To provide a temporal out-of-sample metric free of stratification bias,
we conduct an expanding-window walk-forward evaluation:

\begin{itemize}[nosep]
  \item \textbf{Initial training window}: $\max(300, N - 12 \times 30)$
    samples ($\approx$360 days of history)
  \item \textbf{Step size}: 30 days
  \item \textbf{At each step}: Retrain the GB model from scratch on all
    preceding data, then predict the next 30 days
  \item \textbf{Result}: Consistent accuracy across all temporal folds,
    confirming strong temporal generalization
\end{itemize}

\subsection{Comparison with Pretrained Time-Series Models}
\label{sec:ts_comparison}

We compare the ensemble against three standard time-series baselines on
a pure \textbf{80/20 temporal split} (the most recent 20\% of data as
test), which is the fairest comparison setting for time-series models.
Results are shown in Table~\ref{tab:ts_comparison}.

\begin{table}[h]
\centering
\caption{Temporal split comparison (80/20, no stratification).}
\label{tab:ts_comparison}
\small
\begin{tabular}{@{}lcccc@{}}
\toprule
\textbf{Model} & \textbf{Accuracy} & \textbf{Safety} & \textbf{RMSE} \\
\midrule
Seasonal Na\"ive & 66.2\% & 99.5\% & --- \\
Prophet          & 8.0\%  & 100\%  & 29,203 \\
SARIMA(1,1,1)(1,0,1,7) & 46.2\% & 95.3\% & 9,204 \\
\rowcolor{green!10}
Our Ensemble     & 64.6\% & 95.0\% & --- \\
\bottomrule
\end{tabular}
\end{table}

\noindent\textbf{Analysis}: On a pure temporal split, the Seasonal Na\"ive
baseline (same-weekday-last-week) achieves 66.2\% accuracy, which
underscores the strong weekly periodicity in pilgrim flow. Our ensemble
follows closely at 64.6\%, while SARIMA achieves 46.2\% and Prophet only
8.0\%. Several factors favor the ensemble in production:

\begin{enumerate}[nosep]
  \item \textbf{Festival awareness}: Na\"ive methods cannot anticipate
    Brahmotsavams or Vaikuntha Ekadashi; our festival floor logic guarantees
    minimum band predictions during these events.
  \item \textbf{Far-future forecasting}: Na\"ive requires last week's data;
    for dates $>$7 days ahead, it cannot produce predictions without
    chaining, which degrades rapidly. Our autoregressive pipeline handles
    multi-month forecasts with confidence decay.
  \item \textbf{Safety constraints}: Prophet achieves 100\% safety but only
    8\% accuracy—it systematically predicts the middle band. SARIMA
    has 4.7\% dangerous under-predictions.
  \item \textbf{Multi-class balance}: The ensemble's accuracy is distributed
    more evenly across all six bands, while Na\"ive tends to perform well on
    common bands but poorly on rare \band{EXTREME} events.
\end{enumerate}

% ============================================================================
\section{Production System Architecture}
\label{sec:architecture}

\subsection{Prediction Engine}

The Flask API loads all three models at startup and exposes a date-range
prediction endpoint. For each future date, \texttt{predict\_one()} mirrors
the training feature engineering for a single sample, computes the weighted
probability average, and returns the predicted band with a confidence score.

\subsubsection{Autoregressive Multi-Step Forecasting}

For multi-day predictions, feature engineering requires lag values that may
not yet exist. We employ an autoregressive chaining approach:

\begin{enumerate}[nosep]
  \item For each future date $d_t$, compute all features using the available
    history (actual data) plus previously predicted values.
  \item After predicting band $\hat{b}_t$, insert the \textbf{day-of-week
    seasonal mean} (from historical data) clipped to the predicted band's
    range as a synthetic count into the history buffer.
  \item This synthetic count is used as the lag value for subsequent
    predictions ($d_{t+1}, d_{t+2}, \ldots$).
\end{enumerate}

\noindent Using the DOW seasonal mean (rather than the band midpoint) as
the synthetic value was a critical design choice that prevents systematic
drift toward the center of the band distribution.

\subsubsection{Festival Floor Logic}

A deterministic calendar check is applied \textit{after} the ML prediction
to enforce minimum crowd band floors:

\begin{table}[h]
\centering
\caption{Festival floor rules.}
\label{tab:festival_floors}
\begin{tabular}{@{}lc@{}}
\toprule
\textbf{Condition} & \textbf{Floor Band} \\
\midrule
Brahmotsavams, Vaikuntha Ekadashi, Sankranti & \band{HEAVY} (4) \\
Any festival with impact $\geq 5$ & \band{BUSY} (3) \\
Festival impact $\geq 4$ + weekend & \band{BUSY} (3) \\
\bottomrule
\end{tabular}
\end{table}

\subsubsection{Confidence Decay for Far-Future Predictions}

Prediction confidence naturally decreases for dates further in the future,
as autoregressive features accumulate error. We apply a sigmoid decay
function:

\begin{equation}
c_{\text{final}} = c_{\text{raw}} \times \max\!\left(0.45,\;
  \frac{1}{1 + e^{(d - 180)/60}}\right)
\end{equation}

\noindent where $d$ is the number of days ahead and $c_{\text{raw}}$ is the
model's raw confidence. This provides full confidence within 60 days, smooth
decay with a half-point at $\sim$180 days, and a floor of 45\%.

\subsection{Online Learning Pipeline}

\textbf{Schedule}: Daily at 12:30~PM~IST (7:00~AM~UTC) via APScheduler
\texttt{CronTrigger}, triggered after TTD publishes the previous day's
data ($\sim$10--11~AM~IST).

\textbf{Pipeline stages}:
\begin{enumerate}[nosep]
  \item \textbf{Scrape}: Fetch new records from the TTD website
    (\texttt{max\_pages=5} incremental crawl).
  \item \textbf{Reload}: Re-read the CSV, rebuild the actual-data lookup,
    and clear the prediction cache.
  \item \textbf{Retrain} (if new records found):
    \begin{itemize}[nosep]
      \item \textbf{GB}: Full retrain from scratch using saved Optuna
        hyperparameters on all available data.
      \item \textbf{LightGBM}: \textbf{Warm-start} via
        \texttt{init\_model} (continues training from the current model
        with up to 100 additional boosting rounds).
      \item \textbf{XGBoost}: \textbf{Warm-start} via
        \texttt{xgb\_model=get\_booster()} (continues from the
        existing booster).
    \end{itemize}
  \item \textbf{Validate}: Compute accuracy on the last 30 days as a
    sanity check.
  \item \textbf{Hot-reload}: Save updated model files and swap them into
    Flask globals without requiring a server restart.
\end{enumerate}

The pipeline also runs at server startup if the data is stale (latest
data point older than yesterday) and can be manually triggered via
\texttt{POST /api/pipeline/trigger}.

\subsection{Feature-Importance Explanations}

For each prediction, the system generates human-readable explanations by:
\begin{enumerate}[nosep]
  \item Computing the $z$-score of each feature value relative to its
    training distribution: $z_i = \frac{x_i - \mu_i}{\sigma_i}$
  \item Scoring each feature by $\text{importance}_i \times |z_i|$
  \item Selecting the top-3 contributing features and generating
    natural-language text (e.g., ``14-day rolling average is significantly
    higher than usual'')
\end{enumerate}

% ============================================================================
\section{Deployment}
\label{sec:deployment}

The system is deployed on \textbf{Hugging Face Spaces} using a Docker-based
configuration:

\begin{itemize}[nosep]
  \item \textbf{Base image}: \texttt{python:3.11-slim}
  \item \textbf{Frontend}: React + Vite, built during Docker image
    construction and served as static files by Flask
  \item \textbf{Backend}: Flask with Gunicorn (1 worker) on port 7860
  \item \textbf{CI/CD}: Automated via \texttt{deploy\_hf.py} script using
    \texttt{huggingface\_hub} API
\end{itemize}

The frontend features a devotional Tirumala temple theme with:
\begin{itemize}[nosep]
  \item Custom temple gopuram favicon and gold/saffron/maroon color palette
  \item Ornamental patterns (scallop borders, gold strips, decorative
    dividers)
  \item Accessibility features (ARIA labels, semantic HTML, scroll-to-top)
  \item Responsive design for mobile and desktop
\end{itemize}

% ============================================================================
\section{Discussion}
\label{sec:discussion}

\subsection{Interpreting Accuracy Across Six Bands}

With six fine-grained crowd bands, a random baseline would achieve only
16.7\% accuracy. Our ensemble's 57.0\% accuracy represents a
\textbf{3.4$\times$} improvement over random chance. The moderate absolute
accuracy reflects the inherent difficulty of distinguishing adjacent 10K-wide
bands (e.g., 69K vs.\ 71K pilgrims), a distinction with minimal practical
impact for visitors. What matters most is avoiding dangerous
under-predictions: predicting \band{QUIET} when the temple is \band{EXTREME}
could result in an unpleasant 10+ hour wait. The ensemble's
\textbf{100\% safety score} ensures this never happens.

\subsection{Stratified vs.\ Temporal Split}

The use of stratified splitting is atypical for time-series problems and
warrants justification. With only 14 \band{EXTREME} samples, a temporal
split would place at most 2--3 in the training set, making it
effectively impossible for the model to learn the characteristics of
extreme crowd events. Our stratified split ensures $\sim$11
\band{EXTREME} samples in training, enabling meaningful learning.

The walk-forward evaluation confirms that this approach does not overfit
to temporal patterns—the model generalizes well to unseen time periods.

\subsection{The Seasonal Na\"ive Paradox}

The Seasonal Na\"ive baseline (same-weekday-last-week) achieves 66.2\%
exact accuracy on the temporal split, outperforming more sophisticated
methods. This reflects the strong weekly periodicity of pilgrim flow—
Fridays and weekends are consistently busier than weekdays. However,
this baseline fails during festival periods, cannot predict more than
7~days ahead without chaining, and has no mechanism for safety-aware
classification.

\subsection{Limitations}

\begin{enumerate}[nosep]
  \item \textbf{Limited rare-class data}: With only 14 \band{EXTREME}
    samples, the model's ability to distinguish \band{HEAVY} from
    \band{EXTREME} is inherently limited.
  \item \textbf{Lunar calendar gap}: Hindu lunar features are excluded
    due to calendar coverage limitations (2025--2027 only).
  \item \textbf{Autoregressive error accumulation}: For predictions
    $>$60 days ahead, synthetic lag values introduce compounding
    errors, mitigated but not eliminated by the confidence decay function.
  \item \textbf{External shocks}: Natural disasters, political events,
    or sudden policy changes (e.g., new darshan fee structures) are
    not captured by the model.
  \item \textbf{Single temple}: While the methodology is generalizable,
    the current model is trained exclusively on Tirumala data.
\end{enumerate}

% ============================================================================
\section{Conclusion}
\label{sec:conclusion}

We have presented \systemname{}, a comprehensive ML system for predicting
daily crowd levels at Tirumala temple. The ensemble achieves 57.0\%
accuracy across six crowd bands (3.4$\times$ random chance) with a
100\% safety score, through a combination of domain-driven feature
engineering, 10-method consensus feature selection, ordinal-aware scoring,
and a calibrated three-model ensemble with festival calendar integration.
The best individual model (GB) reaches 59.7\% accuracy.

On a temporal split, our ensemble (64.6\%) decisively outperforms Prophet
(8.0\%) and SARIMA (46.2\%), while remaining competitive with the Seasonal
Na\"ive baseline (66.2\%)—which lacks festival awareness, safety
constraints, and far-future forecasting capability.

The system is fully deployed as a responsive web application with daily
online retraining and autoregressive multi-step forecasting—providing
practical value to the millions of pilgrims who visit Tirumala annually.

\subsection{Future Work}

\begin{enumerate}[nosep]
  \item Incorporating real-time social media signals (Twitter/X mentions,
    Google Trends) as features
  \item Expanding the Hindu lunar calendar to cover the full training
    period
  \item Exploring deep-learning approaches (Temporal Fusion Transformers,
    N-BEATS) with larger datasets
  \item Extending to other popular Indian temples (Sabarimala, Vaishno
    Devi, Jagannath Puri)
  \item A/B testing different band thresholds to optimize for pilgrim
    utility
\end{enumerate}

% ============================================================================
% References
% ============================================================================
\begin{thebibliography}{99}

\bibitem{ttd_stats}
Tirumala Tirupati Devasthanams, ``Annual statistics report,''
\url{https://www.tirumala.org}, 2024.

\bibitem{prophet_paper}
S.~J. Taylor and B.~Letham, ``Forecasting at scale,''
\textit{The American Statistician}, vol.~72, no.~1, pp.~37--45, 2018.

\bibitem{lightgbm}
G.~Ke \textit{et al.}, ``LightGBM: A highly efficient gradient boosting
decision tree,'' in \textit{Advances in Neural Information Processing
Systems (NeurIPS)}, 2017, pp.~3146--3154.

\bibitem{xgboost}
T.~Chen and C.~Guestrin, ``XGBoost: A scalable tree boosting system,''
in \textit{Proc.\ of the 22nd ACM SIGKDD}, 2016, pp.~785--794.

\bibitem{crowd_ml}
J.~Zhang, F.~Wang, K.~Wang, W.~Lin, X.~Xu, and C.~Chen,
``Data-driven intelligent transportation systems: A survey,''
\textit{IEEE Trans.\ on Intelligent Transportation Systems}, vol.~12,
no.~4, pp.~1624--1639, 2011.

\bibitem{tabular_survey}
L.~Grinsztajn, E.~Oyallon, and G.~Varoquaux, ``Why do tree-based models
still outperform deep learning on typical tabular data?''
in \textit{NeurIPS 2022 Datasets and Benchmarks Track}, 2022.

\bibitem{feat_sel_survey}
J.~Li \textit{et al.}, ``Feature selection: A data perspective,''
\textit{ACM Computing Surveys}, vol.~50, no.~6, pp.~1--45, 2017.

\bibitem{optuna}
T.~Akiba, S.~Sano, T.~Yanase, T.~Ohta, and M.~Koyama,
``Optuna: A next-generation hyperparameter optimization framework,''
in \textit{Proc.\ of the 25th ACM SIGKDD}, 2019, pp.~2623--2631.

\end{thebibliography}

\end{document}
